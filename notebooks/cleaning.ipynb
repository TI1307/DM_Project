{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TI1307/DM_Project/blob/main/notebooks/cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9yj3VWpGMmu"
      },
      "source": [
        "# Data Preprocessing and cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uupI1cs_HURi"
      },
      "source": [
        "# Data Quality **Issues**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHfcT4SPhg_o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib_inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcCH4s6gHq9l",
        "outputId": "1c7aae3a-b2d1-4613-bb05-1e4d609e681a"
      },
      "outputs": [],
      "source": [
        "########    LIBRARY INVENTORY TABLE      ###############\n",
        "LIBRARY_INVENTORY_REAL= pd.read_excel(\"../data/LIBRARY INVENTORY.xlsx\")\n",
        "print ('Number of instance in the LIBRARY INVENTORY' , (LIBRARY_INVENTORY_REAL.shape[0]))\n",
        "print ('Number of attributes in the LIBRARY INVENTORY' , (LIBRARY_INVENTORY_REAL.shape[1]))\n",
        "print(LIBRARY_INVENTORY_REAL.head(3))\n",
        "print ('-'*20)\n",
        "########  LIBRARY_CARALOGUE TABLE     ###############\n",
        "LIBRARY_CATALOGUE_REAL= pd.read_excel(\"../data/library catalogue.xlsx\")\n",
        "print ('Number of instance in the LIBRARY CARALOGUE' , (LIBRARY_CATALOGUE_REAL.shape[0]))\n",
        "print ('Number of attributes in the LIBRARY INVENTORY' , (LIBRARY_CATALOGUE_REAL.shape[1]))\n",
        "print ('-'*20)\n",
        "#######    BORROWING TABLE             ###########################\n",
        "BORROWINGS_REAL= pd.read_excel(\"../data/Borrowings .xlsx\")\n",
        "print ('Number of instance in the BORROWINGS TABLE ' , (BORROWINGS_REAL.shape[0]))\n",
        "print ('Number of attributes in the BORROWINGS TABLE ' , (BORROWINGS_REAL.shape[1]))\n",
        "print(BORROWINGS_REAL.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Copy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LIBRARY_INVENTORY =LIBRARY_INVENTORY_REAL.copy()\n",
        "LIBRARY_CATALOGUE =LIBRARY_CATALOGUE_REAL.copy()\n",
        "BORROWINGS =BORROWINGS_REAL.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Cleaning Functions**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YALjdQnvK4Os"
      },
      "source": [
        "### **Missing Values**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-bZQLTfMC1x"
      },
      "outputs": [],
      "source": [
        "# gives a summery of missing values\n",
        "def missing_values_summary(df):\n",
        "  missing_count = df.isnull().sum()\n",
        "  missing_percent = (missing_count/ len(df))*100\n",
        "\n",
        "  summery = pd.DataFrame({\n",
        "      'missing_count': missing_count,\n",
        "      'missing_percent': missing_percent\n",
        "  })\n",
        "  summery = summery.sort_values('missing_percent', ascending=False)\n",
        "  return summery\n",
        "import pandas as pd\n",
        "\n",
        "def handle_missing_values(df, strategy_dict):\n",
        "    \"\"\"\n",
        "    Fill missing values in a DataFrame according to a strategy dictionary.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): Input dataframe\n",
        "        strategy_dict (dict): {column_name: strategy}, where strategy can be:\n",
        "            - 'mean'   → fill numeric with mean\n",
        "            - 'median' → fill numeric with median\n",
        "            - 'mode'   → fill categorical with mode\n",
        "            - value    → fill with this value directly\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with missing values handled\n",
        "    \"\"\"\n",
        "    for col, strategy in strategy_dict.items():\n",
        "        if strategy == 'mean':\n",
        "            df[col] = df[col].fillna(df[col].mean())\n",
        "        elif strategy == 'median':\n",
        "            df[col] = df[col].fillna(df[col].median())\n",
        "        elif strategy == 'mode':\n",
        "            df[col] = df[col].fillna(df[col].mode()[0])\n",
        "        else:\n",
        "            # Use the provided value\n",
        "            df[col] = df[col].fillna(strategy)\n",
        "    return df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSgccCApK79v"
      },
      "source": [
        "### **Outliers**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtf3J3MYLGio"
      },
      "source": [
        "### **Duplicate Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8rMlEuPUM7e"
      },
      "outputs": [],
      "source": [
        "def checkDuplicat (df, table_name,  keep=False):\n",
        "    dup=df.duplicated()\n",
        "    dup_count=dup.sum()\n",
        "    print(f'Number of duplicate rows in {table_name} table is = %d' % (dup_count))\n",
        "    if dup_count > 0:\n",
        "      print (f'\\n Duplicare row in the table {table_name}:')\n",
        "      dup_rows=df[dup]\n",
        "      for idx in dup_rows.index:\n",
        "          print(f'\\n row number :{idx}')\n",
        "          print(df.loc[idx])\n",
        "          print('-' * 50)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v87kaoBnLKGS"
      },
      "source": [
        "### **Aggregation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piq_nPOpLNt8"
      },
      "source": [
        "### **Sampling**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKwxfO5QLRjo"
      },
      "source": [
        "### **Discretization**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dates formating \n",
        "def format_dates(df, date_columns):\n",
        "    for col in date_columns:\n",
        "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "    return df\n",
        "\n",
        "def borrowing_duration(df,Date_prêt,Date_retour):\n",
        "    format_dates(df, [Date_prêt,Date_retour])\n",
        "    df['borrowing duration']=(df[Date_retour]-df[Date_prêt]).dt.days\n",
        "    return "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj1jx0N3Omh6"
      },
      "source": [
        "# **Borowing Table**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table info**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleaningg the borrowing table\n",
        "# table name : BORROWINGS\n",
        "\n",
        "print ('Number of instance in the BORROWINGS TABLE ' , (BORROWINGS.shape[0]))\n",
        "print ('Number of attributes in the BORROWINGS TABLE ' , (BORROWINGS.shape[1]))\n",
        "print(BORROWINGS.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Missing Values & Check Duplicate**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcXdFBNIOkzQ",
        "outputId": "be40e73d-c14c-408f-e097-97fb1ea28ddc"
      },
      "outputs": [],
      "source": [
        "# summery about missing values :\n",
        "print(missing_values_summary(BORROWINGS))\n",
        "\n",
        "#check duplicate :\n",
        "checkDuplicat(BORROWINGS , \"BORROWINGS TABLE \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we drop Date réservation because more then 60% (98%) of its value is missing \n",
        "BORROWINGS=BORROWINGS.drop(['Date réservation'],axis=1) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Outliers**:\n",
        "\n",
        "First we convert the dates from string to date type , then calculate borrowing duration ( Date_retour- date_pret) , to get numurical values so we can detect outliers using box blot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "borrowing_duration(BORROWINGS,'Date prêt','Date retour')\n",
        "BORROWINGS = BORROWINGS.drop(['Date prêt', 'Date retour'], axis=1)\n",
        "print(BORROWINGS.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BORROWINGS.boxplot(column='borrowing duration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BORROWINGS[BORROWINGS['borrowing duration']>250]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpjX5VdJVyn6"
      },
      "source": [
        "# **LIBRARY INVENTORY**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table info**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleaningg the LIBRARY INVENTORY table\n",
        "# table name : LIBRARY_INVENTORY\n",
        "\n",
        "print ('Number of instance in the LIBRARY_INVENTORY TABLE ' , (LIBRARY_INVENTORY.shape[0]))\n",
        "print ('Number of attributes in the LIBRARY_INVENTORY TABLE ' , (LIBRARY_INVENTORY.shape[1]))\n",
        "print(LIBRARY_INVENTORY.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Missing Values & Check Duplicate**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8N6X1K0WGe9",
        "outputId": "b9882afa-6694-4534-af3c-244fa0e62c94"
      },
      "outputs": [],
      "source": [
        "# summery about missing values :\n",
        "print(missing_values_summary(LIBRARY_INVENTORY))\n",
        "\n",
        "#check duplicate :\n",
        "checkDuplicat(LIBRARY_INVENTORY, \"LIBRARY_INVENTORY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Outliers**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "LIBRARY_INVENTORY[\"Date d'édition\"] = pd.to_numeric(LIBRARY_INVENTORY[\"Date d'édition\"], errors=\"coerce\")\n",
        "LIBRARY_INVENTORY.boxplot(column=[\"Prix\",\"Date d'édition\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LIBRARY_INVENTORY[LIBRARY_INVENTORY[\"Prix\"]>40000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LIBRARY_INVENTORY[LIBRARY_INVENTORY[\"Date d'édition\"]>10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFVboj7bubIG"
      },
      "source": [
        "# **LIBRARY_CATALOGUE**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**table info**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleaningg the LIBRARY_CATALOGUE table\n",
        "# table name : LIBRARY_CATALOGUE\n",
        "\n",
        "print ('Number of instance in the LIBRARY_CATALOGUE TABLE ' , (LIBRARY_CATALOGUE.shape[0]))\n",
        "print ('Number of attributes in the LIBRARY_CATALOGUE TABLE ' , (LIBRARY_CATALOGUE.shape[1]))\n",
        "print(LIBRARY_CATALOGUE.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Missing Values & check Duplicate**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTKf_JZTuaJU",
        "outputId": "8263d0cb-4dd0-48ff-ef6f-be19069fb4be"
      },
      "outputs": [],
      "source": [
        "# summery about missing values :\n",
        "print(missing_values_summary(LIBRARY_CATALOGUE))\n",
        "\n",
        "#check duplicate :\n",
        "checkDuplicat(LIBRARY_CATALOGUE, \"LIBRARY_CATALOGUE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Outliers**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LIBRARY_CATALOGUE.boxplot(column='Nbr. Exp.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LIBRARY_CATALOGUE[LIBRARY_CATALOGUE['Nbr. Exp.']>120]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Merge Tables**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**data cleaning and preparation for text matching**\n",
        "\n",
        "handling the Title column in the three tables because it’s the common column used for merging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean titles (remove extra spaces, lowercase for matching)\n",
        "def clean_title(title):\n",
        "    return str(title).strip().lower()\n",
        "\n",
        "BORROWINGS['Titre_clean'] = BORROWINGS['Titre'].apply(clean_title) \n",
        "LIBRARY_CATALOGUE['Titre_clean'] = LIBRARY_CATALOGUE['Titre'].apply(clean_title)\n",
        "LIBRARY_INVENTORY['Titre_clean'] = LIBRARY_INVENTORY['Titre'].apply(clean_title)\n",
        "#Stores the result in a new column called Titre_clean, which is used for merging.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Aggregation_**\n",
        "\n",
        "For the Inventory table, instead of having multiple rows for the same book, we grouped them into a single row by adding a Total_copies column and storing all copy statuses in an array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all columns in LIBRARY_INVENTORY\n",
        "all_columns = LIBRARY_INVENTORY.columns.tolist()\n",
        "\n",
        "# Columns you want to aggregate specially\n",
        "agg_columns = {\n",
        "    'N° inventaire': 'count',  \n",
        "    'Date de réception': 'min',\n",
        "    'Statut': lambda x: ', '.join(x.dropna().unique())\n",
        "}\n",
        "\n",
        "# For other columns, just take the first value \n",
        "for col in all_columns:\n",
        "    if col not in agg_columns and col != 'Titre_clean':\n",
        "        agg_columns[col] = 'first'  \n",
        "\n",
        "# Perform aggregation\n",
        "inventory_summary = LIBRARY_INVENTORY.groupby('Titre_clean').agg(agg_columns).rename(columns={\n",
        "    'N° inventaire': 'Total_Copies',\n",
        "    'Date de réception': 'First_Acquisition',\n",
        "    'Statut': 'Copy_Statuses'\n",
        "}).reset_index()\n",
        "\n",
        "print(\"Length before aggregation:\", len(LIBRARY_INVENTORY))\n",
        "print(\"Length after aggregation:\", len(inventory_summary))\n",
        "print(inventory_summary.columns)\n",
        "print (LIBRARY_INVENTORY.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Merge Tables_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Keep only FIRST occurrence of each title in catalog\n",
        "catalog_unique = LIBRARY_CATALOGUE.drop_duplicates(subset=['Titre_clean'], keep='first')\n",
        "print(f\"Catalog: {len(LIBRARY_CATALOGUE)} → {len(catalog_unique)} unique titles\")\n",
        "\n",
        "#Merge borrowing with catalog (by Title  )\n",
        "merged_1 = pd.merge(\n",
        "    BORROWINGS,\n",
        "    catalog_unique ,\n",
        "    how='left',\n",
        "    left_on='Titre_clean' , \n",
        "    right_on='Titre_clean', \n",
        "    suffixes=('_borrowings', '_catalogue'))\n",
        "#Merge result with inventory (by Title)\n",
        "final_merged = pd.merge(\n",
        "    merged_1,\n",
        "    inventory_summary,\n",
        "    how='left',\n",
        "    left_on='Titre_clean', \n",
        "    right_on='Titre_clean', \n",
        "    suffixes=('_merged1', '_inventory'))\n",
        "\n",
        "#clean up columns\n",
        "#becuae Titre exist in the three tables Pandas automatically adds suffixes to distinguish them so we need to remove them .\n",
        "if 'Titre_catalogue' in final_merged.columns:\n",
        "  final_merged.drop('Titre_catalogue', axis=1 , inplace=True)\n",
        "if 'Titre_inventory' in final_merged.columns:\n",
        "  final_merged.drop('Titre_inventory', axis=1 , inplace=True)\n",
        "\n",
        "#keep original title from borrowing table\n",
        "final_merged.rename (columns={'Titre_borrowings' :'Titre' }, inplace=True)\n",
        "\n",
        "#remove the titre_clean column\n",
        "final_merged.drop('Titre_clean' , axis=1 , inplace=True)\n",
        "print(f\"Original borrowing rows: {len(BORROWINGS)}\")\n",
        "print(f\"Final merged rows: {len(final_merged)}\")\n",
        "print(f\"Columns: {list(final_merged.columns)}\")\n",
        "\n",
        "# Check for unmatched books\n",
        "#Check borrowings not in catalog:\n",
        "unmatched_borrowings = final_merged[final_merged['ISBN, ISSN...'].isna()]\n",
        "print(f\"Borrowings without catalog match: {len(unmatched_borrowings)}\")\n",
        "#Check borrowings not in inventory:\n",
        "unmatched_inventory = final_merged[final_merged['Total_Copies'].isna()]\n",
        "print(f\"Borrowings without inventory match: {len(unmatched_inventory)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Save Final Table_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to CSV\n",
        "final_merged.to_csv('../data/unified_library_data.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# Save to Excel\n",
        "final_merged.to_excel('../data/unified_library_data.xlsx', index=False)\n",
        "\n",
        "print(\" Merge complete!\")\n",
        "print(f\"Final dataset: {len(final_merged)} rows × {len(final_merged.columns)} columns\")\n",
        "print(f\"File saved: unified_library_data.csv\")\n",
        "UNIFIED_LIBRARY_DATA = pd.read_excel (\"unified_library_data.xlsx\")\n",
        "\n",
        "checkDuplicat(UNIFIED_LIBRARY_DATA, \"LIBRARY_CATALOGUE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_End-to-end catalogue cleaning and feature engineering (Cote + ISBN)_**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Load the data and initial exploration_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('../data/unified_library_data.csv')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ORIGINAL DATA\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Extract all existing COTE digits (first 3 digits)_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"STEP 1: EXTRACT COTE DIGITS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def extract_cote_digits(cote_str):\n",
        "    \"\"\"Extract first 3 digits from Cote\"\"\"\n",
        "    if pd.isna(cote_str) or str(cote_str).strip() == '':\n",
        "        return None\n",
        "    \n",
        "    # Find all digits in the string\n",
        "    digits = re.findall(r'\\d+', str(cote_str))\n",
        "    if not digits:\n",
        "        return None\n",
        "    \n",
        "    # Get first 3 digits\n",
        "    first_number = digits[0]\n",
        "    if len(first_number) >= 3:\n",
        "        return first_number[:3]\n",
        "    elif len(first_number) > 0:\n",
        "        # Pad with zeros if less than 3 digits (e.g., \"5\" becomes \"500\")\n",
        "        return first_number.ljust(3, '0')\n",
        "    return None\n",
        "\n",
        "# Extract digits\n",
        "df['cote_digits'] = df['Cote'].apply(extract_cote_digits)\n",
        "\n",
        "print(\"✓ Extracted cote_digits column\")\n",
        "print(f\"\\nUnique Cote digits found: {df['cote_digits'].nunique()}\")\n",
        "print(\"\\nAll existing Cote digits in your data:\")\n",
        "print(sorted(df['cote_digits'].dropna().unique()))\n",
        "print(\"\\nSample:\")\n",
        "print(df[['Cote', 'cote_digits']].head(10))\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Map Selected COTE Digits to Topics_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"STEP 2: MAP SELECTED COTE DIGITS TO FRENCH TOPICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Only for these 21 codes:\n",
        "# ['004', '005', '006', '150', '230', '350', '380',\n",
        "#  '510', '511', '512', '515', '518', '519',\n",
        "#  '570', '610', '611', '616', '621', '658', '681', '808']\n",
        "\n",
        "topic_mapping_fr = {\n",
        "    '004': \"Informatique générale\",\n",
        "    '005': \"Programmation / logiciels\",\n",
        "    '006': \"Intelligence artificielle / traitement automatique\",\n",
        "    '150': \"Psychologie\",\n",
        "    '230': \"Christianisme / religion\",\n",
        "    '350': \"Administration publique\",\n",
        "    '380': \"Commerce / communication\",\n",
        "    '510': \"Mathématiques générales\",\n",
        "    '511': \"Principes généraux des maths\",\n",
        "    '512': \"Algèbre\",\n",
        "    '515': \"Analyse / calcul\",\n",
        "    '518': \"Méthodes numériques / calcul scientifique\",\n",
        "    '519': \"Probabilités et statistiques appliquées\",\n",
        "    '570': \"Sciences de la vie / biologie\",\n",
        "    '610': \"Médecine / santé\",\n",
        "    '611': \"Anatomie\",\n",
        "    '616': \"Maladies / pathologie\",\n",
        "    '621': \"Génie / ingénierie\",\n",
        "    '658': \"Gestion / management\",\n",
        "    '681': \"Appareils de précision / informatique appliquée\",\n",
        "    '808': \"Techniques d’écriture / composition\"\n",
        "}\n",
        "\n",
        "def map_to_topic_fr(cote_digit):\n",
        "    \"\"\"Map selected 3-digit Cote code to a French topic label.\"\"\"\n",
        "    if pd.isna(cote_digit) or cote_digit is None:\n",
        "        return \"Inconnu\"\n",
        "    return topic_mapping_fr.get(cote_digit, \"Autre (hors sélection)\")\n",
        "\n",
        "# New column on df (still the working copy)\n",
        "df[\"topic_fr\"] = df[\"cote_digits\"].apply(map_to_topic_fr)\n",
        "\n",
        "print(\"✓ Created 'topic_fr' column using the 21 selected codes\")\n",
        "print(\"\\nTopic_fr distribution:\")\n",
        "print(df[\"topic_fr\"].value_counts())\n",
        "print(\"\\nSample:\")\n",
        "print(df[[\"Cote\", \"cote_digits\", \"topic_fr\"]].head(15))\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Check missing \"Inconnu\" and \"Autre (hors sélection)\" values in topic column_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"CHECK TOPIC_FR COVERAGE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) How many rows per topic\n",
        "print(\"\\nTopic_fr distribution:\")\n",
        "print(df[\"topic_fr\"].value_counts(dropna=False))\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2) Rows with missing topic (Inconnu)\n",
        "mask_inconnu = df[\"topic_fr\"] == \"Inconnu\"\n",
        "print(f\"Rows with 'Inconnu': {mask_inconnu.sum()}\")\n",
        "print(df.loc[mask_inconnu, [\"Cote\", \"cote_digits\", \"topic_fr\"]].head(10))\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3) Rows mapped as other (hors sélection)\n",
        "mask_autre = df[\"topic_fr\"] == \"Autre (hors sélection)\"\n",
        "print(f\"Rows with 'Autre (hors sélection)': {mask_autre.sum()}\")\n",
        "print(df.loc[mask_autre, [\"Cote\", \"cote_digits\", \"topic_fr\"]].head(10))\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_ISBN cleaning and light mapping_**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Extract all existing ISBN group digits_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"STEP 3B: ANALYSE EXISTING ISBN GROUP DIGITS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def extract_group_digit(isbn):\n",
        "    if pd.isna(isbn):\n",
        "        return None\n",
        "    s = str(isbn)\n",
        "    # use cleaned version if available\n",
        "    s = re.sub(r\"[^0-9Xx]\", \"\", s)\n",
        "    if not s:\n",
        "        return None\n",
        "    if s.startswith((\"978\", \"979\")) and len(s) >= 4:\n",
        "        return s[3]  # group after 978/979\n",
        "    return s[0]     # older style\n",
        "\n",
        "df[\"isbn_group_digit\"] = df[\"isbn_clean\"].apply(\n",
        "    lambda x: extract_group_digit(x) if x is not None else None\n",
        ")\n",
        "\n",
        "print(\"Distribution des chiffres de groupe ISBN (d’après les données réelles) :\")\n",
        "print(df[\"isbn_group_digit\"].value_counts(dropna=False))\n",
        "print(\"\\nExemples :\")\n",
        "print(df[[\"ISBN, ISSN...\", \"isbn_clean\", \"isbn_group_digit\"]].head(15))\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Map existing ISBN group digits into country/region labels (create isbn_country_fr)_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"STEP 3C: MAPPER LES GROUPES ISBN EN FRANÇAIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Dictionnaire basé UNIQUEMENT sur les chiffres présents : 0,1,2,3,9\n",
        "isbn_group_mapping_fr = {\n",
        "    \"0\": \"Pays anglophones\",\n",
        "    \"1\": \"Pays anglophones\",\n",
        "    \"2\": \"Pays francophones\",\n",
        "    \"3\": \"Pays germanophones\",\n",
        "    \"9\": \"Pays scandinaves / autres\"\n",
        "}\n",
        "\n",
        "def map_isbn_country_fr(group_digit, has_isbn):\n",
        "    \"\"\"\n",
        "    Retourne un libellé français :\n",
        "      - 'Sans ISBN' si aucun ISBN nettoyé\n",
        "      - Libellé précis si groupe connu\n",
        "      - 'Autre région' si groupe non mappé mais ISBN présent\n",
        "    \"\"\"\n",
        "    if not has_isbn:\n",
        "        return \"Sans ISBN\"\n",
        "    if group_digit is None:\n",
        "        return \"Autre région\"\n",
        "    return isbn_group_mapping_fr.get(group_digit, \"Autre région\")\n",
        "\n",
        "# Nouvelle colonne : région en français\n",
        "df[\"isbn_country_fr\"] = df.apply(\n",
        "    lambda row: map_isbn_country_fr(\n",
        "        row[\"isbn_group_digit\"],\n",
        "        row[\"isbn_clean\"] is not None\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"✓ Colonne 'isbn_country_fr' créée\\n\")\n",
        "print(df[\"isbn_country_fr\"].value_counts(dropna=False))\n",
        "print(\"\\nExemples :\")\n",
        "print(df[[\"ISBN, ISSN...\", \"isbn_clean\", \"isbn_group_digit\", \"isbn_country_fr\"]].head(15))\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Check missing / “autre” / “sans ISBN”_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"STEP 3D: QUALITÉ DES DONNÉES ISBN\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nDistribution de isbn_country_fr :\")\n",
        "print(df[\"isbn_country_fr\"].value_counts(dropna=False))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Combien de lignes sans ISBN du tout\n",
        "mask_sans_isbn = df[\"isbn_country_fr\"] == \"Sans ISBN\"\n",
        "print(f\"Lignes sans ISBN : {mask_sans_isbn.sum()}\")\n",
        "\n",
        "# Lignes classées 'Autre région'\n",
        "mask_autre = df[\"isbn_country_fr\"] == \"Autre région\"\n",
        "print(f\"Lignes 'Autre région' : {mask_autre.sum()}\")\n",
        "\n",
        "# Lignes où isbn_clean est manquant (vraiment aucun code)\n",
        "mask_isbn_clean_na = df[\"isbn_clean\"].isna()\n",
        "print(f\"Lignes avec isbn_clean manquant : {mask_isbn_clean_na.sum()}\")\n",
        "print(\"\\nExemples sans ISBN :\")\n",
        "print(df.loc[mask_sans_isbn, [\"ISBN, ISSN...\", \"isbn_clean\", \"isbn_country_fr\"]].head(10))\n",
        "print(\"\\nExemples 'Autre région' :\")\n",
        "print(df.loc[mask_autre, [\"ISBN, ISSN...\", \"isbn_clean\", \"isbn_group_digit\", \"isbn_country_fr\"]].head(10))\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**_Final table with new extracted column_**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"STEP 4 (VERSION FINALE): NOUVELLE TABLE + EXPORT EXCEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import os\n",
        "os.makedirs(\"../data\", exist_ok=True)\n",
        "\n",
        "# Colonnes à garder : toutes les anciennes + un sous-ensemble de nouvelles\n",
        "new_cols_keep = [\"cote_digits\", \"topic_fr\", \"isbn_clean\", \"isbn_type\", \"isbn_country_fr\"]\n",
        "\n",
        "# On part de df (avec toutes les colonnes)\n",
        "all_cols = list(df.columns)\n",
        "\n",
        "# S'assurer que les colonnes choisies existent\n",
        "final_cols = []\n",
        "for c in all_cols:\n",
        "    if c in new_cols_keep or c not in [\n",
        "        \"cote_digits\", \"topic_fr\",\n",
        "        \"isbn_clean\", \"isbn_type\",\n",
        "        \"isbn_country\", \"isbn_group_digit\",\n",
        "        \"isbn_country_fr\"\n",
        "    ]:\n",
        "        final_cols.append(c)\n",
        "# Puis ajouter explicitement les nouvelles qu'on veut à la fin (ordre lisible)\n",
        "for c in new_cols_keep:\n",
        "    if c not in final_cols:\n",
        "        final_cols.append(c)\n",
        "\n",
        "df_final = df[final_cols].copy()\n",
        "\n",
        "output_path = \"../data/unified_library_with_topics_isbn.xlsx\"\n",
        "df_final.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"\\n✓ Nouvelle table Excel sauvegardée dans : {output_path}\")\n",
        "print(f\"Shape: {df_final.shape}\")\n",
        "\n",
        "print(\"\\nHEAD DE LA NOUVELLE TABLE:\")\n",
        "print(df_final.head())\n",
        "\n",
        "print(\"\\nCOLONNES MARQUÉES (OLD/NEW):\")\n",
        "for col in df_final.columns:\n",
        "    tag = \"NEW\" if col in new_cols_keep else \"OLD\"\n",
        "    print(f\"- {col}  -->  {tag}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DM_ENV",
      "language": "python",
      "name": "dm_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
